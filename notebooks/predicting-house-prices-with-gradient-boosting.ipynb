{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":482,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0b62b8f9787eea5dd789dffac23559df915f2eee"},"cell_type":"code","source":"# Keep random values consistent\n\nnp.random.seed(0)","execution_count":483,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Read in the train and test data into a pandas dataframe\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":484,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e14dc5b855738acfb46355b198a95a32fa2d8841"},"cell_type":"code","source":"# Gather brief overview of training data\n\ntrain.head()","execution_count":485,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5f7b9be213f753af573ad975e96be65c096381b7"},"cell_type":"code","source":"# Set sample ids as dataframe indices for train, and test sets\ntrain.set_index(\"Id\", inplace=True)\ntest.set_index(\"Id\", inplace=True)","execution_count":486,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"10ee024d304b91149e3882272f9511d011d8326a"},"cell_type":"code","source":"# Since most features consist of string values which can't be read into a machine \n# learning algorithm, let's convert them all to indicator values\n\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)","execution_count":487,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0444bbfa0fbc6f0c1b1d77e31be71b8d59df611"},"cell_type":"code","source":"# Check to see if any features are missing values and view some of those feature's values\n\nfor feature in train.columns:\n    if train[feature].isnull().any():\n        print(train[feature].head())","execution_count":488,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c3d95ab82d53d420b2ddd4674aa83cae12d688bb"},"cell_type":"code","source":"# Modify training and test data so that any missing values are converted to the corresponding \n# feature's median value\n\ntrain.fillna(train.median(), inplace=True)\ntest.fillna(test.median(), inplace=True)","execution_count":489,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ed1c9859f728c833fc4cec8338472ffde0c5ca0"},"cell_type":"code","source":"# Confirm how many features we have\n\nprint(\"Number of features:\", train.shape[1])","execution_count":490,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"8fc5a7d9a6cfe12649dc76cd3717e8ab8767e88d"},"cell_type":"code","source":"# To minimize the number of features, let's identify all those with a p-value <= 0.05\n\nfrom scipy.stats import pearsonr\n\nrelevant_features = []\nfor feature in train.columns:\n    if feature != \"SalePrice\":\n        p_value = pearsonr(train[feature], train[\"SalePrice\"])[1]\n        if p_value <= 0.05:\n            relevant_features.append(feature)\nprint(\"Number of relevant features:\", len(relevant_features))","execution_count":491,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"beba540979cb4d4739cebae42b0e30845b0905c7"},"cell_type":"code","source":"# Randomly partition our training set into a training and development set \n# with a 9:1 ratio\n\ntrain_shuffled = train.sample(frac=1, random_state=0)\nmask = np.random.rand(len(train)) < 0.9\ntrain = train_shuffled[mask]\ndev = train_shuffled[~mask]","execution_count":492,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6ee7158a5721ce5cd8341dbe5b6abd13144a16e2"},"cell_type":"code","source":"# Partition train, dev, and test sets into predictors and responses, \n# only using features identified as relevant as predictors\nX_train = train[relevant_features]\nY_train = train[\"SalePrice\"]\nX_dev = dev[relevant_features]\nY_dev = dev[\"SalePrice\"]\nX_test = test[relevant_features]","execution_count":493,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83764cfafef1017e2c6375baa6163da1c6bf8b7b"},"cell_type":"code","source":"# Train several different regressors on our training data and aggregate them to a list\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\nrr_model = Ridge(random_state=0).fit(X_train, Y_train)\nsvr_linear_model = SVR(kernel=\"linear\").fit(X_train, Y_train)\nsvr_rbf_model = SVR(kernel=\"rbf\").fit(X_train, Y_train)\nrfr_model = RandomForestRegressor(random_state=0).fit(X_train, Y_train)\ngbr_model = GradientBoostingRegressor(random_state=0).fit(X_train, Y_train)\n\nmodels = [rr_model, svr_linear_model, svr_rbf_model, rfr_model, gbr_model]","execution_count":494,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef1eced5e1e4656d0e2e6552f63b3833af67159a"},"cell_type":"code","source":"# Identify the \"chosen\" model out of our collection of models as the one that has the \n# highest R^2 score on the development set\n\nchosen_model = None\nhighest_score = 0\n\nfor model in models:\n    score = model.score(X_dev, Y_dev)\n    if score > highest_score:\n        chosen_model = model\n        highest_score = score","execution_count":495,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f32c1feeb09d72120893777b24298310b3f78786"},"cell_type":"code","source":"# Submit chosen model predictions on test set\n\npredictions = [{\"Id\": sample, \n                \"SalePrice\": chosen_model.predict(X_test.loc[sample]\n                                                        .values\n                                                        .reshape(1, len(X_test.loc[sample])))[0]} \n               for sample in X_test.index]\nsubmission = pd.DataFrame(predictions)\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":496,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9442673313487448e597d652d6c96d2b283b71ac"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}