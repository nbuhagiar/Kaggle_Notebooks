{"cells":[{"metadata":{"_uuid":"eeeba7702615635d5ead80dff0bd79294aad044c"},"cell_type":"markdown","source":"# CNN Pneumonia Diagnoser"},{"metadata":{"_uuid":"3e348e4e951f6a26f8437bde6e5d0f63791683ca"},"cell_type":"markdown","source":"Let's build a machine learning model to diagnose pneumonia in patients given an X-ray of their chest using convolutional neural networks. Gratitude must be expressed to [Faizunnabi](https://www.kaggle.com/faizunnabi) for his excellent kernel [Diagnose Pneumonia](https://www.kaggle.com/faizunnabi/diagnose-pneumonia), which served as an inspiration for me to try and build a CNN for this task."},{"metadata":{"_uuid":"cc4958d326a99eaeac7618f93fe49ecc361dba6c"},"cell_type":"markdown","source":"## Data Exploration"},{"metadata":{"_uuid":"4b29cd34ab4945ca9e6d17f5f9652f49d9a87d22"},"cell_type":"markdown","source":"Let's begin by loading all necessary packages and taking a look at where the data files are located."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\nimport os\nprint(os.listdir(\"../input/chest_xray/chest_xray/\"))\nprint(os.listdir(\"../input/chest_xray/chest_xray/train/\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Before building a machine learning model, let's view some of the X-ray images in our training set."},{"metadata":{"trusted":true,"_uuid":"6681340eb9fc27f0a13544861c51504f119634cc"},"cell_type":"code","source":"file_loc = \"../input/chest_xray/chest_xray/\"\ntrain_n = os.listdir(file_loc + \"train/NORMAL/\")\ntrain_p = os.listdir(file_loc + \"train/PNEUMONIA/\")\nfig, axarr = plt.subplots(3, 2, figsize=(16, 16))\naxarr[0][0].set_title(\"Normal Sample Cases\")\naxarr[0][1].set_title(\"Pneumonia Sample Cases\")\nfor i in range(3):\n    axarr[i][0].imshow(cv2.imread(file_loc + \"train/NORMAL/\" + train_n[i]))\n    axarr[i][0].axis(\"off\")\n    axarr[i][1].imshow(cv2.imread(file_loc + \"train/PNEUMONIA/\" + train_p[i]))\n    axarr[i][1].axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a89d69a19e8e02d5318ba37cf0b79eebfaf62d7c"},"cell_type":"markdown","source":"As we can see, images in this dataset are focused square on the chest of a given patient, all coming in different sizes. It is also not obvious, at least to me, what visual features distinguish a case of pneumonia and a \"normal\" case. Let's now see what the distribution in our training data is between normal and pneumonia cases."},{"metadata":{"trusted":true,"_uuid":"0b3098fe32f23fd6a03a70a22ced7ecb5139b0af"},"cell_type":"code","source":"sns.barplot(x=[\"Normal\", \"Pneumonia\"], y=[len(train_n), len(train_p)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24f06f883e2562aeccb7ab94f2931304dee8c7aa"},"cell_type":"markdown","source":"As we can see, there are roughly three times as many pneumonia cases as there are normal cases in our training set. Let's also take a peek at the number of images we actually have in each of our train, validation, and test sets."},{"metadata":{"trusted":true,"_uuid":"845613199811b1dc4891b784c6a010a2a7353124"},"cell_type":"code","source":"train_images = train_n + train_p\ntrain_images = [img for img in train_images if img != \".DS_Store\"]\nval_images = os.listdir(file_loc + \"val/NORMAL/\") + os.listdir(file_loc + \"val/PNEUMONIA/\")\nval_images = [img for img in val_images if img != \".DS_Store\"]\ntest_images = os.listdir(file_loc + \"test/NORMAL/\") + os.listdir(file_loc + \"test/PNEUMONIA/\")\ntest_images = [img for img in test_images if img != \".DS_Store\"]\n\nsns.barplot(x=[\"Train\", \"Validation\", \"Test\"], y=[len(train_images), len(val_images), len(test_images)])\nprint(\"There are {} images in the training set.\".format(len(train_images)))\nprint(\"There are {} images in the validation set.\".format(len(val_images)))\nprint(\"There are {} images in the test set.\".format(len(test_images)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53af6539c62155ca73fe09145cc3820b1fdb9be1"},"cell_type":"markdown","source":"As expected, there are much more training samples then validation and test samples. We will augment the data in our training set to offer further images for a convolutional neural network to train from."},{"metadata":{"_uuid":"c440c207cbfe0ddadb645b9ba7ff4c9c8d2c8a7d"},"cell_type":"markdown","source":"## Training a Convolutional Neural Network"},{"metadata":{"_uuid":"a776abbd81a8d6aebb1c7b1fecb7d3a9cb8619cd"},"cell_type":"markdown","source":"Let's now build data generators for this dataset. We will transform all images to be 256x256 pixels, as well as rescale their values to be between 0 and 1. We will also perform data augmentation on our training data by shifting these images horizontally and vertically by 10% of their total width and height respectively, as well as setting a zoom range to be 0.1."},{"metadata":{"trusted":true,"_uuid":"1fbb131c9ddaf138c7eb804ee41509c3a3df136e"},"cell_type":"code","source":"image_height, image_width = 256, 256\nbatch_size=32\n\ndata_generator_train = ImageDataGenerator(rescale=1/255, \n                                          width_shift_range=0.1, \n                                          height_shift_range=0.1, \n                                          zoom_range=0.1)\ntrain = data_generator_train.flow_from_directory(directory=file_loc + \"train/\", \n                                                 target_size=(image_height, \n                                                              image_width), \n                                                 class_mode=\"binary\", \n                                                 batch_size=batch_size)\n\ndata_generator_val = ImageDataGenerator(rescale=1/255)\nval = data_generator_val.flow_from_directory(directory=file_loc + \"val/\", \n                                             target_size=(image_height, \n                                                          image_width), \n                                             class_mode=\"binary\", \n                                             batch_size=batch_size)\n\ndata_generator_test = ImageDataGenerator(rescale=1/255)\ntest = data_generator_test.flow_from_directory(directory=file_loc + \"test/\", \n                                               target_size=(image_height, \n                                                            image_width), \n                                               class_mode=\"binary\", \n                                               batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30a2138b2cb70bc3609247f6060be0304c5d638d"},"cell_type":"markdown","source":"Let's now design the structure of our CNN, using a convolution, max pooling, and dropout layer, as well as a dense output layer with a sigmoid activation function outputting the probability of a given image belonging to a particular class. The Adam optimizer will be used with a 1e-5 learning rate and binary cross entropy loss function. The only performance metric that we will keep track of for this study is accuracy. Let's now train the model for 10 epochs, reducing the learning rate by a factor of 0.1 if the validation loss has not improved for 2 epochs."},{"metadata":{"trusted":true,"_uuid":"6aeaf34d3d2782277dd114de3051ae91649f9425"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64, \n                 (3, 3), \n                 input_shape=(image_height, image_width, 3), \n                 activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(optimizer=Adam(lr=1e-5), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()\nnum_epochs = 10\nhistory = model.fit_generator(train, \n                              steps_per_epoch=5216//batch_size, \n                              epochs=num_epochs, \n                              validation_data=val, \n                              validation_steps=16, \n                              callbacks=[ReduceLROnPlateau(patience=2, verbose=1)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2061a70ac7f0f4d3c926d9372318728c9085086a"},"cell_type":"markdown","source":"## Analyzing our Model"},{"metadata":{"_uuid":"c9e965374d05ec0fc0d50a3e41037edb4ba3ccf3"},"cell_type":"markdown","source":"With our model trained for 10 epochs, let's see how the model's loss and accuracy on both the training and validation set evolved throughout the training procedure."},{"metadata":{"trusted":true,"_uuid":"8dc92681989b535cf852adffc021c790df802428"},"cell_type":"code","source":"fig, axarr = plt.subplots(1, 2, figsize=(24, 8))\naxarr[0].set_xlabel(\"Number of Epochs\")\naxarr[0].set_ylabel(\"Loss\")\nsns.lineplot(x=range(1, num_epochs+1), y=history.history[\"loss\"], label=\"Train\", ax=axarr[0])\nsns.lineplot(x=range(1, num_epochs+1), y=history.history[\"val_loss\"], label=\"Validation\", ax=axarr[0])\naxarr[1].set_xlabel(\"Number of Epochs\")\naxarr[1].set_ylabel(\"Accuracy\")\naxarr[1].set_ylim(0, 1)\nsns.lineplot(x=range(1, num_epochs+1), y=history.history[\"acc\"], label=\"Train\", ax=axarr[1])\nsns.lineplot(x=range(1, num_epochs+1), y=history.history[\"val_acc\"], label=\"Validation\", ax=axarr[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab93716150a7161c647112318dcd7a1c3c6e4b7f"},"cell_type":"markdown","source":"As we can see, our losses decreased and accuracy scores increased throughout the training procedure. The validation curves are alot less smooth then their training counterparts, but this is most likely due to their being only 16 images in the validation set. Let's calculate our model's accuracy on the test set."},{"metadata":{"trusted":true,"_uuid":"876c5b2ea1c845d1e423e1866a5304bc35a192c0"},"cell_type":"code","source":"test_results = model.evaluate_generator(test, steps=624//batch_size)\nprint(\"The model has a test accuracy of {}.\".format(test_results[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be382369163d1b54041dd1e13e89dfcd916fa102"},"cell_type":"markdown","source":"## Final Remarks"},{"metadata":{"_uuid":"767fc4257fff401bb524dbecf599185651281d5c"},"cell_type":"markdown","source":"Training a simple convolutional neural network, we were able to build a pneumonia diagnoser with a test accuracy of around 88%. Training a more complex model for a greater number of epochs, as well as having more data available, we could most likely further improve upon these results. Regardless, not only was this a very interesting and rewarding task to work on, but it further proved to me how effective convolutional neural networks can be for image recognition."},{"metadata":{"trusted":true,"_uuid":"48cc2107b10c59702b305060a616d4b5218fb7ce"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}